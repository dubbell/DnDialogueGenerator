{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "from data_collection import training_set\n",
    "from transformers import GPT2Tokenizer\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "961c8e5dd40545d4b575b0a2cd94e0a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/610 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset None/None to /home/linulun/.cache/huggingface/datasets/AlekseyKorshuk___parquet/AlekseyKorshuk--synthetic-romantic-characters-3b16d8e672467bfe/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbded7f44b99439ab3d3742351b8876c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bc8742d6b394cb7a4c8232ab74956cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/7.90M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c25e3d86a53f4544b42823487a6fe6a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "200d97b44a194144a8721c5340591394",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/5744 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parquet downloaded and prepared to /home/linulun/.cache/huggingface/datasets/AlekseyKorshuk___parquet/AlekseyKorshuk--synthetic-romantic-characters-3b16d8e672467bfe/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d0ecca37ddf484bb3cda35afbf7e6e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7b3235158304f9eb79b4d69752c3696",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/610 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset None/None to /home/linulun/.cache/huggingface/datasets/AlekseyKorshuk___parquet/AlekseyKorshuk--synthetic-friendly-characters-8195740b6ede92c1/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07251bb9fc364c9cb2887b8dce83f838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d93cf03ec59f44769a8c72c277e999d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/5.61M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9da0ed869c474fa49af77037f690c7ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26c466ab4d504424b6d5791f94669abf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/3871 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parquet downloaded and prepared to /home/linulun/.cache/huggingface/datasets/AlekseyKorshuk___parquet/AlekseyKorshuk--synthetic-friendly-characters-8195740b6ede92c1/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec2983c607084431929749e81d6e6e49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "799ead65d1ce4e17a20b8f03fb3a394b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/608 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset None/None to /home/linulun/.cache/huggingface/datasets/AlekseyKorshuk___parquet/AlekseyKorshuk--synthetic-fight-characters-dbee9baf48903647/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad7a77bc9f65473b8138d16248fbc297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7e65a0d081e41828238844113c60350",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/11.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9055db685dc42ac9224ed7c2c5e7c6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dac8ec3007b413992a32bfa6a33efe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/8053 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset parquet downloaded and prepared to /home/linulun/.cache/huggingface/datasets/AlekseyKorshuk___parquet/AlekseyKorshuk--synthetic-fight-characters-dbee9baf48903647/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3023747be38c4c54941d00038cab1079",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "romantic_data = load_dataset(\"AlekseyKorshuk/synthetic-romantic-characters\")[\"train\"]\n",
    "friendly_data = load_dataset(\"AlekseyKorshuk/synthetic-friendly-characters\")[\"train\"]\n",
    "fight_data = load_dataset(\"AlekseyKorshuk/synthetic-fight-characters\")[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': \"*Elijah walks up to you, holding a tray of freshly baked muffins.* Hey there! Care for a muffin? They're fresh out of the oven and they're my new favorite recipe! *He grins eagerly and offers you a muffin.* And if you're interested, I can give you the recipe too! I love sharing my baking tips and recipes with others, it's just so much fun!\", 'role': 'character'}, {'content': \"*I take a muffin, my nose already starting to twitch from the smell.* Thanks, I'd love to have one. And if you don't mind, I'd love to get a recipe from you sometime. I'm always looking to try new baked goods.\", 'role': 'user'}, {'content': \"*Elijah's face lights up with excitement.* Of course, I'd be happy to share my recipe with you! I'll even write it down right now for you. I love sharing my recipes with others, it's just so much fun! *He pulls out a small notebook from his pocket and begins to write out the recipe for you.* I'll make a note to include any substitutions or adjustments for high altitude baking.\", 'role': 'character'}, {'content': \"*I take a bite of the muffin, savoring the sweet flavor.* This is amazing, thank you. I'll definitely have to try this recipe out sometime.\", 'role': 'user'}, {'content': \"*Elijah grins, looking ecstatic.* I'm so glad you like it! I would love to hear about any modifications you make, so feel free to reach out to me. And if you ever want to bake together, just let me know! I love spending time in the kitchen with others, it's one of my favorite things to do.\", 'role': 'character'}, {'content': \"*I chuckle.* I'll definitely keep that in mind. Thank you again for the muffin and the recipe.\", 'role': 'user'}, {'content': \"*Elijah nods, looking pleased.* You're welcome! I'm always happy to share my passion for baking with others. And remember, the kitchen is always a good place to be, whether you're cooking or just hanging out with friends. Maybe we can have a baking session some time? I promise, it'll be loads of fun!\", 'role': 'character'}]\n"
     ]
    }
   ],
   "source": [
    "train_data = training_set([\"romantic\", \"friendly\", \"fight\"])\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['name', 'categories', 'personalities', 'description', 'conversation']\n"
     ]
    }
   ],
   "source": [
    "dialogue_dataset = []\n",
    "for dataset in [romantic_data, friendly_data, fight_data]:\n",
    "    for conversation in dataset:\n",
    "        dialogue_dataset.append(conversation)\n",
    "    \n",
    "print(list(dialogue_dataset[0].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In total, there are 17668 conversations, 1565 conversation categories, and 777 types of personalities.\n",
      "5 most common categories:\n",
      "\t3796\tromance\n",
      "\t2574\tfantasy\n",
      "\t1621\tadventure\n",
      "\t1578\tcomedy\n",
      "\t1337\tentertainment\n",
      "5 most common personalities:\n",
      "\t1582\tadventurous\n",
      "\t1211\tempathetic\n",
      "\t970\tmysterious\n",
      "\t956\tcalm\n",
      "\t805\tcreative\n",
      "\n",
      "In romantic_data, there are 5744 conversations, 582 conversation categories, and 244 types of personalities.\n",
      "5 most common categories:\n",
      "\t3645\tromance\n",
      "\t754\tfantasy\n",
      "\t752\ttravel\n",
      "\t740\tmusic\n",
      "\t591\tart\n",
      "5 most common personalities:\n",
      "\t774\tadventurous\n",
      "\t558\tcreative\n",
      "\t507\tcharming\n",
      "\t475\timaginative\n",
      "\t470\tcharismatic\n",
      "\n",
      "In friendly_data, there are 3871 conversations, 531 conversation categories, and 266 types of personalities.\n",
      "5 most common categories:\n",
      "\t689\tsupport\n",
      "\t671\tentertainment\n",
      "\t495\tcomedy\n",
      "\t440\teducation\n",
      "\t352\twellness\n",
      "5 most common personalities:\n",
      "\t682\tempathetic\n",
      "\t369\tcompassionate\n",
      "\t363\tadventurous\n",
      "\t359\tcalm\n",
      "\t339\tcurious\n",
      "\n",
      "In fight_data, there are 8053 conversations, 1169 conversation categories, and 634 types of personalities.\n",
      "5 most common categories:\n",
      "\t1785\tfantasy\n",
      "\t1266\tadventure\n",
      "\t1067\tcomedy\n",
      "\t958\tmystery\n",
      "\t609\taction\n",
      "5 most common personalities:\n",
      "\t789\tsarcastic\n",
      "\t716\tmysterious\n",
      "\t519\tcunning\n",
      "\t501\trebellious\n",
      "\t489\tmischievous\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def count_data(name, dataset):\n",
    "    category_counter = Counter()\n",
    "    personality_counter = Counter()\n",
    "    for conversation in dataset:\n",
    "        category_counter.update([c.lower() for c in conversation[\"categories\"]])\n",
    "        personality_counter.update([p.lower() for p in filter(lambda p: \" \" not in p, conversation[\"personalities\"])])\n",
    "\n",
    "    print(f\"In {name}, there are {len(dataset)} conversations, {len(category_counter)} conversation categories, and {len(personality_counter)} types of personalities.\")\n",
    "    print(\"5 most common categories:\")\n",
    "    for name, count in category_counter.most_common(5):\n",
    "        print(\"\\t\" + str(count) + \"\\t\" + str(name))\n",
    "    print(\"5 most common personalities:\")\n",
    "    for name, count in personality_counter.most_common(5):\n",
    "        print(\"\\t\" + str(count) + \"\\t\" + str(name))\n",
    "    print()\n",
    "    \n",
    "\n",
    "for name, dataset in zip([\"total\", \"romantic_data\", \"friendly_data\", \"fight_data\"], [dialogue_dataset, romantic_data, friendly_data, fight_data]):\n",
    "    count_data(name, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Personality statistics:\n",
      "4.364161195381481 0.591856041784797 2 10\n",
      "\n",
      "Category statistics:\n",
      "2.91283676703645 0.2858611286202068 2 4\n",
      "\n",
      "Conversation statistics:\n",
      "7 7\n",
      "10.0 3.1622776601683795 4 13\n",
      "50.0 0.0 50 50\n",
      "\n",
      "Total length statistics:\n",
      "1715.6083314466832 466.0260407307866 473 4622\n",
      "312.28656327824314 84.09137336614894 82 792\n"
     ]
    }
   ],
   "source": [
    "print(\"Personality statistics:\")\n",
    "personality_counts = [len(item[\"personalities\"]) for item in dialogue_dataset]\n",
    "print(np.mean(personality_counts), np.std(personality_counts), min(personality_counts), max(personality_counts))\n",
    "\n",
    "print(\"\\nCategory statistics:\")\n",
    "category_counts = [len(item[\"categories\"]) for item in dialogue_dataset]\n",
    "print(np.mean(category_counts), np.std(category_counts), min(category_counts), max(category_counts))\n",
    "\n",
    "print(\"\\nConversation statistics:\")\n",
    "line_counts = [len(item[\"conversation\"]) for item in dialogue_dataset]\n",
    "print(min(line_counts), max(line_counts))\n",
    "line_lengths = [len(line) for item in dialogue_dataset for line in item]\n",
    "print(np.mean(line_lengths), np.std(line_lengths), min(line_lengths), max(line_lengths))\n",
    "conversation_lengths = [sum(len(line) for line in item) for item in dialogue_dataset]\n",
    "print(np.mean(conversation_lengths), np.std(conversation_lengths), min(conversation_lengths), max(conversation_lengths))\n",
    "\n",
    "print(\"\\nTotal length statistics:\")\n",
    "char_lengths = []\n",
    "for item in dialogue_dataset:\n",
    "    temp = sum(len(line[\"content\"]) for line in item[\"conversation\"])\n",
    "    temp += sum(len(pers) for pers in item[\"personalities\"])\n",
    "    temp += sum(len(cat) for cat in item[\"categories\"])\n",
    "    char_lengths.append(temp)\n",
    "print(np.mean(char_lengths), np.std(char_lengths), min(char_lengths), max(char_lengths))\n",
    "\n",
    "token_lengths = []\n",
    "for item in dialogue_dataset:\n",
    "    temp = sum(len(line[\"content\"].split(\" \")) for line in item[\"conversation\"])\n",
    "    temp += sum(len(pers.split(\" \")) for pers in item[\"personalities\"])\n",
    "    temp += sum(len(cat.split(\" \")) for cat in item[\"categories\"])\n",
    "    token_lengths.append(temp)\n",
    "print(np.mean(token_lengths), np.std(token_lengths), min(token_lengths), max(token_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/linulun/.cache/huggingface/datasets/AlekseyKorshuk___parquet/AlekseyKorshuk--synthetic-romantic-characters-3b16d8e672467bfe/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5f58b21c14249e0a84ade757d0ec309",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/linulun/.cache/huggingface/datasets/AlekseyKorshuk___parquet/AlekseyKorshuk--synthetic-friendly-characters-8195740b6ede92c1/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca452ba05c1140a99ce26b43cd896160",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (/home/linulun/.cache/huggingface/datasets/AlekseyKorshuk___parquet/AlekseyKorshuk--synthetic-fight-characters-dbee9baf48903647/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5a783be6e3d4b9c838990d1b48dc6e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "test = training_set([\"romantic\", \"friendly\", \"fight\"], tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(test, open(\"dataset.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<data_collection.DialogueDataset object at 0x728e22b6b290>\n"
     ]
    }
   ],
   "source": [
    "print(pickle.load(open(\"dataset.p\", \"rb\")))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
