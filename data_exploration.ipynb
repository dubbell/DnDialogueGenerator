{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "romantic_data = load_dataset(\"AlekseyKorshuk/synthetic-romantic-characters\")[\"train\"]\n",
    "friendly_data = load_dataset(\"AlekseyKorshuk/synthetic-friendly-characters\")[\"train\"]\n",
    "fight_data = load_dataset(\"AlekseyKorshuk/synthetic-fight-characters\")[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['name', 'categories', 'personalities', 'description', 'conversation']\n"
     ]
    }
   ],
   "source": [
    "dialogue_dataset = []\n",
    "for dataset in [romantic_data, friendly_data, fight_data]:\n",
    "    for conversation in dataset:\n",
    "        dialogue_dataset.append(conversation)\n",
    "    \n",
    "print(list(dialogue_dataset[0].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In total, there are 17668 conversations, 1565 conversation categories, and 777 types of personalities.\n",
      "5 most common categories:\n",
      "\t3796\tromance\n",
      "\t2574\tfantasy\n",
      "\t1621\tadventure\n",
      "\t1578\tcomedy\n",
      "\t1337\tentertainment\n",
      "5 most common personalities:\n",
      "\t1582\tadventurous\n",
      "\t1211\tempathetic\n",
      "\t970\tmysterious\n",
      "\t956\tcalm\n",
      "\t805\tcreative\n",
      "\n",
      "In romantic_data, there are 5744 conversations, 582 conversation categories, and 244 types of personalities.\n",
      "5 most common categories:\n",
      "\t3645\tromance\n",
      "\t754\tfantasy\n",
      "\t752\ttravel\n",
      "\t740\tmusic\n",
      "\t591\tart\n",
      "5 most common personalities:\n",
      "\t774\tadventurous\n",
      "\t558\tcreative\n",
      "\t507\tcharming\n",
      "\t475\timaginative\n",
      "\t470\tcharismatic\n",
      "\n",
      "In friendly_data, there are 3871 conversations, 531 conversation categories, and 266 types of personalities.\n",
      "5 most common categories:\n",
      "\t689\tsupport\n",
      "\t671\tentertainment\n",
      "\t495\tcomedy\n",
      "\t440\teducation\n",
      "\t352\twellness\n",
      "5 most common personalities:\n",
      "\t682\tempathetic\n",
      "\t369\tcompassionate\n",
      "\t363\tadventurous\n",
      "\t359\tcalm\n",
      "\t339\tcurious\n",
      "\n",
      "In fight_data, there are 8053 conversations, 1169 conversation categories, and 634 types of personalities.\n",
      "5 most common categories:\n",
      "\t1785\tfantasy\n",
      "\t1266\tadventure\n",
      "\t1067\tcomedy\n",
      "\t958\tmystery\n",
      "\t609\taction\n",
      "5 most common personalities:\n",
      "\t789\tsarcastic\n",
      "\t716\tmysterious\n",
      "\t519\tcunning\n",
      "\t501\trebellious\n",
      "\t489\tmischievous\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def count_data(name, dataset):\n",
    "    category_counter = Counter()\n",
    "    personality_counter = Counter()\n",
    "    for conversation in dataset:\n",
    "        category_counter.update([c.lower() for c in conversation[\"categories\"]])\n",
    "        personality_counter.update([p.lower() for p in filter(lambda p: \" \" not in p, conversation[\"personalities\"])])\n",
    "\n",
    "    print(f\"In {name}, there are {len(dataset)} conversations, {len(category_counter)} conversation categories, and {len(personality_counter)} types of personalities.\")\n",
    "    print(\"5 most common categories:\")\n",
    "    for name, count in category_counter.most_common(5):\n",
    "        print(\"\\t\" + str(count) + \"\\t\" + str(name))\n",
    "    print(\"5 most common personalities:\")\n",
    "    for name, count in personality_counter.most_common(5):\n",
    "        print(\"\\t\" + str(count) + \"\\t\" + str(name))\n",
    "    print()\n",
    "    \n",
    "\n",
    "for name, dataset in zip([\"total\", \"romantic_data\", \"friendly_data\", \"fight_data\"], [dialogue_dataset, romantic_data, friendly_data, fight_data]):\n",
    "    count_data(name, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Personality statistics:\n",
      "4.364161195381481 0.591856041784797 2 10\n",
      "\n",
      "Category statistics:\n",
      "2.91283676703645 0.2858611286202068 2 4\n",
      "\n",
      "Conversation statistics:\n",
      "7 7\n",
      "10.0 3.1622776601683795 4 13\n",
      "50.0 0.0 50 50\n",
      "\n",
      "Total length statistics:\n",
      "1715.6083314466832 466.0260407307866 473 4622\n",
      "312.28656327824314 84.09137336614894 82 792\n"
     ]
    }
   ],
   "source": [
    "print(\"Personality statistics:\")\n",
    "personality_counts = [len(item[\"personalities\"]) for item in dialogue_dataset]\n",
    "print(np.mean(personality_counts), np.std(personality_counts), min(personality_counts), max(personality_counts))\n",
    "\n",
    "print(\"\\nCategory statistics:\")\n",
    "category_counts = [len(item[\"categories\"]) for item in dialogue_dataset]\n",
    "print(np.mean(category_counts), np.std(category_counts), min(category_counts), max(category_counts))\n",
    "\n",
    "print(\"\\nConversation statistics:\")\n",
    "line_counts = [len(item[\"conversation\"]) for item in dialogue_dataset]\n",
    "print(min(line_counts), max(line_counts))\n",
    "line_lengths = [len(line) for item in dialogue_dataset for line in item]\n",
    "print(np.mean(line_lengths), np.std(line_lengths), min(line_lengths), max(line_lengths))\n",
    "conversation_lengths = [sum(len(line) for line in item) for item in dialogue_dataset]\n",
    "print(np.mean(conversation_lengths), np.std(conversation_lengths), min(conversation_lengths), max(conversation_lengths))\n",
    "\n",
    "print(\"\\nTotal length statistics:\")\n",
    "char_lengths = []\n",
    "for item in dialogue_dataset:\n",
    "    temp = sum(len(line[\"content\"]) for line in item[\"conversation\"])\n",
    "    temp += sum(len(pers) for pers in item[\"personalities\"])\n",
    "    temp += sum(len(cat) for cat in item[\"categories\"])\n",
    "    char_lengths.append(temp)\n",
    "print(np.mean(char_lengths), np.std(char_lengths), min(char_lengths), max(char_lengths))\n",
    "\n",
    "token_lengths = []\n",
    "for item in dialogue_dataset:\n",
    "    temp = sum(len(line[\"content\"].split(\" \")) for line in item[\"conversation\"])\n",
    "    temp += sum(len(pers.split(\" \")) for pers in item[\"personalities\"])\n",
    "    temp += sum(len(cat.split(\" \")) for cat in item[\"categories\"])\n",
    "    token_lengths.append(temp)\n",
    "print(np.mean(token_lengths), np.std(token_lengths), min(token_lengths), max(token_lengths))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
